{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc03c0d6-4f72-493f-bb89-3ed8f1ca3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.core import UTCDateTime\n",
    "from collections import defaultdict\n",
    "import pygmt\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a07b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_delay(trace: rf.rfstream.RFTrace) -> float:\n",
    "    return trace.times()[np.argmax(trace.data)] - (\n",
    "        trace.stats.onset - trace.stats.starttime\n",
    "    )\n",
    "\n",
    "\n",
    "def quality_filter(stream: rf.RFStream) -> rf.RFStream:\n",
    "    \"\"\" \"\n",
    "    Applies various final quality controlls to the RFs\n",
    "    \"\"\"\n",
    "    # Drop transverse component\n",
    "    stream = stream.select(channel=\"??R\")\n",
    "\n",
    "    # Count initial number of stations\n",
    "    nstations = len(stream.stack())\n",
    "\n",
    "    # Trim to a reasonable time length\n",
    "    stream = stream.trim2(-5, 10, reftime=\"onset\")\n",
    "    \n",
    "    initial_number = len(stream)\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        # Only keep traces where largest arrival is positive\n",
    "        if trace[np.argmax(trace.data)] < 0:\n",
    "            continue\n",
    "        # Only keep traces where largest arrival is within 2 seconds\n",
    "        if peak_delay(trace) > 2:\n",
    "            continue\n",
    "        # Only keep traces with slope_ratio > 5\n",
    "        if trace.stats.slope_ratio < 5:\n",
    "            continue\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "\n",
    "    # Only keep stations with 10 or more traces\n",
    "    rf_station_dict = {\n",
    "        k: v.sort([\"back_azimuth\"]) for k, v in rf_station_dict.items() if len(v) >= 10\n",
    "    }\n",
    "\n",
    "    final_number = 0\n",
    "    for v in rf_station_dict.values():\n",
    "        final_number += len(v)\n",
    "    print(f\"{len([v for v in rf_station_dict.values() if len(v) > 0])}/{nstations} stations kept after quality control\")\n",
    "    print(f\"{final_number}/{initial_number} radial RFs kept after quality control\")\n",
    "    return sum(rf_station_dict.values(), start=rf.RFStream())\n",
    "\n",
    "\n",
    "def plot_map(stream: rf.RFStream, save_dir=\".\"):\n",
    "    ln_min, ln_max = (112, 155)\n",
    "    lt_min, lt_max = (-46, -8)\n",
    "\n",
    "    lats = np.zeros(len(stream), dtype=float)\n",
    "    lons = np.zeros_like(lats, dtype=float)\n",
    "    nets = np.zeros_like(lats, dtype=str)\n",
    "    delays = np.zeros_like(lats, dtype=float)\n",
    "\n",
    "    for i, trace in enumerate(stream):\n",
    "        lats[i] = trace.meta.station_latitude\n",
    "        lons[i] = trace.meta.station_longitude\n",
    "        nets[i] = trace.meta.network\n",
    "        delays[i] = trace.stats.delay\n",
    "\n",
    "    fig = pygmt.Figure()\n",
    "    fig.basemap(region=[ln_min, ln_max, lt_min, lt_max], frame=True)\n",
    "    fig.coast(shorelines=1, land=\"#ffffe6\", water=\"#e6ffff\", borders=\"2/1p,grey\")\n",
    "\n",
    "    markers = \"dhist\"\n",
    "    marker = random.choice(markers)\n",
    "    pygmt.makecpt(cmap=\"turbo\", series=[delays.min(), delays.max()])\n",
    "\n",
    "    fig.plot(\n",
    "        x=lons,\n",
    "        y=lats,\n",
    "        style=f\"{marker}c\",\n",
    "        fill=delays,\n",
    "        cmap=True,\n",
    "        size=np.full_like(lons, 0.5),\n",
    "    )\n",
    "    fig.colorbar(frame=\"af+lDelay Time TPsb (s)\")\n",
    "    mapfile = os.path.join(save_dir, \"delay_map.pdf\")\n",
    "    fig.savefig(mapfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86d2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of networks for which we have RFs\n",
    "dataroot = \"/g/data/ha3/am3591\"\n",
    "networks = [\n",
    "    net[:2]\n",
    "    for net in os.listdir(dataroot)\n",
    "    if len(net.split(\"-\")[0]) == 2 and net.split(\"-\")[1] == \"analysis\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c2e9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1F\n",
      "Could not process network 1F. Moving on...\n",
      "E3\n",
      "Could not process network E3. Moving on...\n",
      "AQ\n",
      "Could not process network AQ. Moving on...\n",
      "1K\n",
      "Could not process network 1K. Moving on...\n",
      "7J\n",
      "Could not process network 7J. Moving on...\n",
      "7E\n",
      "Could not process network 7E. Moving on...\n",
      "W1\n",
      "Could not process network W1. Moving on...\n",
      "AU\n",
      "29/87 stations kept after quality control\n",
      "475/1937 radial RFs kept after quality control\n",
      "7B\n",
      "Could not process network 7B. Moving on...\n",
      "7Q\n",
      "No run found for network 7Q.\n",
      "Could not process network 7Q. Moving on...\n",
      "7D\n",
      "Could not process network 7D. Moving on...\n",
      "7M\n",
      "Could not process network 7M. Moving on...\n",
      "7F\n",
      "Could not process network 7F. Moving on...\n",
      "3G\n",
      "Could not process network 3G. Moving on...\n",
      "7G\n",
      "Could not process network 7G. Moving on...\n",
      "7W\n",
      "Could not process network 7W. Moving on...\n",
      "7X\n",
      "Could not process network 7X. Moving on...\n",
      "7U\n",
      "Could not process network 7U. Moving on...\n",
      "7V\n",
      "Could not process network 7V. Moving on...\n",
      "E2\n",
      "Could not process network E2. Moving on...\n",
      "7K\n",
      "Could not process network 7K. Moving on...\n",
      "E1\n",
      "Could not process network E1. Moving on...\n",
      "7T\n",
      "Could not process network 7T. Moving on...\n",
      "6K\n",
      "Could not process network 6K. Moving on...\n"
     ]
    }
   ],
   "source": [
    "# Grab the latest receiver functions from each network\n",
    "rfstream = rf.RFStream()  # Stream with every RF\n",
    "rfstacks = rf.RFStream()  # Stream with station stacks\n",
    "for net in networks:\n",
    "# for net in [\"AU\"]:\n",
    "    print(net)\n",
    "    network_dir = os.path.join(dataroot, f\"{net}-analysis\")\n",
    "    try:\n",
    "        latest_run = max(\n",
    "            [\n",
    "                os.path.join(network_dir, d)\n",
    "                for d in os.listdir(network_dir)\n",
    "                if os.path.isdir(os.path.join(network_dir, d))\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"No run found for network {net}.\")\n",
    "        continue\n",
    "\n",
    "    # Grab the latest .h5 file - should be the outputs of qc\n",
    "    h5_file = max(\n",
    "        [\n",
    "            os.path.join(latest_run, f)\n",
    "            for f in os.listdir(latest_run)\n",
    "            if os.path.splitext(f)[1] == \".h5\"\n",
    "        ],\n",
    "        key=os.path.getmtime,\n",
    "    )\n",
    "\n",
    "    stream = rf.read_rf(h5_file, format='h5')\n",
    "    try:\n",
    "        stream = quality_filter(stream)\n",
    "    except:\n",
    "        print(f\"Could not process network {net}. Moving on...\")\n",
    "        continue\n",
    "    rfstream += stream\n",
    "\n",
    "    # Station dictionary\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    stacks = rf.RFStream()\n",
    "    for trace in stream:\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "    for k, v in rf_station_dict.items():\n",
    "        plot_name = os.path.join(latest_run, f\"{k}.pdf\")\n",
    "        fig = v.plot_rf(fname=plot_name,\n",
    "            fig_width=4,\n",
    "            fillcolors=(\"green\", None),\n",
    "            trace_height=0.1,\n",
    "            scale=3,\n",
    "            show_vlines=True,\n",
    "            trim=(-2, 6),\n",
    "        )  # this figure needs some bits to be moved around\n",
    "        stacks += v.stack() # stack stations individually, otherwise coordinates also get stacked\n",
    "\n",
    "    # Get delay of each stack and plot\n",
    "    for trace in stacks:\n",
    "        trace.stats[\"delay\"] = peak_delay(trace)\n",
    "    stacks = stacks.sort([\"delay\"])\n",
    "    plot_name = os.path.join(latest_run, f\"stacks.pdf\")\n",
    "    fig = stacks.plot_rf(fname=plot_name,\n",
    "        fig_width=4,\n",
    "        fillcolors=(\"green\", None),\n",
    "        trace_height=0.1,\n",
    "        scale=3,\n",
    "        show_vlines=True,\n",
    "        trim=(-2, 6),\n",
    "        info=None,\n",
    "    ) # customise this plot to use a colourmap\n",
    "    rfstacks += stacks\n",
    "\n",
    "    # Plot map\n",
    "    plot_map(stacks, latest_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ef1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the full map\n",
    "now = UTCDateTime().strftime(format=\"%Y%m%d_%H%M%S\")\n",
    "outdir = os.path.join(dataroot, \"ALL-analysis\", now)\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "plot_map(rfstacks, outdir)\n",
    "\n",
    "# Save the delay times in txt file\n",
    "with open(os.path.join(outdir, \"delays.txt\"), \"w\") as f:\n",
    "    for stack in rfstacks:\n",
    "        f.write(f\"{stack.meta.network:4}\\t{stack.meta.station:6}\\t{stack.meta.station_longitude}\\t{stack.meta.station_latitude}\\t{stack.stats.delay:.3f}\\n\")\n",
    "\n",
    "# Save the final RFs and stacks\n",
    "rfstream.write(os.path.join(outdir, \"rfstream.h5\"), format=\"H5\")\n",
    "rfstacks.write(os.path.join(outdir, \"rfstacks.h5\"), format=\"H5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2f046d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = stream.select(channel=\"??R\")\n",
    "ids = set(tr.id for tr in stream)\n",
    "np.mean([tr.data for tr in stream if tr.id == id[0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b44773d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (286,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m ids:\n\u001b[0;32m----> 2\u001b[0m     np\u001b[39m.\u001b[39;49marray([tr\u001b[39m.\u001b[39;49mdata \u001b[39mfor\u001b[39;49;00m tr \u001b[39min\u001b[39;49;00m stream \u001b[39mif\u001b[39;49;00m tr\u001b[39m.\u001b[39;49mid \u001b[39m==\u001b[39;49m \u001b[39mid\u001b[39;49m])\n\u001b[1;32m      3\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (286,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "for id in ids:\n",
    "    np.array([tr.data for tr in stream if tr.id == id])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "952b8340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (683,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1990,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (1999,),\n",
       " (2000,),\n",
       " (2000,)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tr.data.shape for tr in stream if tr.id == id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400c0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aussedthick",
   "language": "python",
   "name": "aussedthick"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
