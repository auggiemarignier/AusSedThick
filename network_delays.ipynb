{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f49661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONWARNINGS=ignore\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONWARNINGS=ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc03c0d6-4f72-493f-bb89-3ed8f1ca3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.core import UTCDateTime\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import pygmt\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a07b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_delay(trace: rf.rfstream.RFTrace) -> float:\n",
    "    return trace.times()[np.argmax(trace.data)] - (\n",
    "        trace.stats.onset - trace.stats.starttime\n",
    "    )\n",
    "\n",
    "\n",
    "def _stack(stream: rf.RFStream) -> rf.RFStream():\n",
    "    \"\"\"\n",
    "    TO BE USED ONLY WHEN STREAM ONLY CONTAINS TRACES FROM THE SAME STATION\n",
    "    RFStream.stack() forces stacking for separate ids, including channels\n",
    "    Access original obspy Stream.stack() to stack BHR and HHR channels\n",
    "    Copies meta data as in RFStream.stack()\n",
    "    \"\"\"\n",
    "    _stream = stream.copy()  # Stream.stack() operates in place\n",
    "    stack = super(rf.RFStream, _stream).stack(group_by=\"{network}.{station}\")\n",
    "    assert len(stack) == 1\n",
    "    tr = stream[0]\n",
    "    data = stack[0].data\n",
    "    header = {}\n",
    "    for entry in (\n",
    "        \"network\",\n",
    "        \"station\",\n",
    "        \"sampling_rate\",\n",
    "        \"phase\",\n",
    "        \"moveout\",\n",
    "        \"station_latitude\",\n",
    "        \"station_longitude\",\n",
    "        \"station_elevation\",\n",
    "        \"processing\",\n",
    "    ):\n",
    "        if entry in tr.stats:\n",
    "            header[entry] = tr.stats[entry]\n",
    "    _tr = rf.rfstream.RFTrace(data=data, header=header)\n",
    "    if \"onset\" in tr.stats:\n",
    "        onset = tr.stats.onset - tr.stats.starttime\n",
    "        _tr.stats.onset = _tr.stats.starttime + onset\n",
    "    return rf.RFStream(_tr)\n",
    "\n",
    "\n",
    "def quality_filter(stream: rf.RFStream) -> rf.RFStream:\n",
    "    \"\"\" \"\n",
    "    Applies various final quality controlls to the RFs\n",
    "    starttime and end time are in seconds relative to onset\n",
    "    \"\"\"\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        # Only keep traces where largest arrival is positive\n",
    "        if trace[np.argmax(np.abs(trace.data))] < 0:\n",
    "            continue\n",
    "        # Only keep traces where largest arrival is within 2 seconds after direct p\n",
    "        delay = peak_delay(trace)\n",
    "        if delay > 2 or delay < 0:\n",
    "            continue\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "\n",
    "    # Only keep stations with 10 or more traces\n",
    "    rf_station_dict = {\n",
    "        k: v.sort([\"back_azimuth\"]) for k, v in rf_station_dict.items() if len(v) >= 10\n",
    "    }\n",
    "\n",
    "    return sum(rf_station_dict.values(), start=rf.RFStream())\n",
    "\n",
    "\n",
    "def plot_map(stream: rf.RFStream, save_dir=\".\", show=False):\n",
    "    region = [112, 155, -46, -8]\n",
    "    ln_min, ln_max, lt_min, lt_max = region\n",
    "    projection = (\n",
    "        f\"M{int(np.mean([ln_min, ln_max]))}/{int(np.mean([lt_min, lt_max]))}/15c\"\n",
    "    )\n",
    "\n",
    "    lats = np.zeros(len(stream), dtype=float)\n",
    "    lons = np.zeros_like(lats, dtype=float)\n",
    "    nets = np.zeros_like(lats, dtype=str)\n",
    "    delays = np.zeros_like(lats, dtype=float)\n",
    "\n",
    "    for i, trace in enumerate(stream):\n",
    "        lats[i] = trace.meta.station_latitude\n",
    "        lons[i] = trace.meta.station_longitude\n",
    "        nets[i] = trace.meta.network\n",
    "        delays[i] = trace.stats.delay\n",
    "\n",
    "    fig = pygmt.Figure()\n",
    "    fig.basemap(region=region, projection=projection, frame=True)\n",
    "    fig.coast(\n",
    "        region=region,\n",
    "        projection=projection,\n",
    "        shorelines=1,\n",
    "        land=\"#ffffe6\",\n",
    "        water=\"#e6ffff\",\n",
    "        borders=\"2/1p,grey\",\n",
    "    )\n",
    "\n",
    "    pygmt.makecpt(cmap=\"plasma\", series=[0, 1])\n",
    "\n",
    "    fig.plot(\n",
    "        region=region,\n",
    "        projection=projection,\n",
    "        x=lons,\n",
    "        y=lats,\n",
    "        style=f\"tc\",\n",
    "        pen=\"1p\",\n",
    "        fill=delays,\n",
    "        cmap=True,\n",
    "        size=np.full_like(lons, 0.3),\n",
    "    )\n",
    "    fig.colorbar(region=region, projection=projection, frame=\"af+lDelay Time TPsb (s)\")\n",
    "    if save_dir is not None:\n",
    "        mapfile = os.path.join(save_dir, \"delay_map.pdf\")\n",
    "        fig.savefig(mapfile)\n",
    "    if show:\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86d2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of networks for which we have RFs\n",
    "try:\n",
    "    dataroot = os.environ[\"DATADIR\"]\n",
    "except KeyError:\n",
    "    dataroot = \"rf_data\"\n",
    "networks = [\n",
    "    net[:2]\n",
    "    for net in os.listdir(dataroot)\n",
    "    if len(net.split(\"-\")[0]) == 2 and net.split(\"-\")[1] == \"analysis\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "237c5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network_rfs(network: str):\n",
    "    \"\"\"\n",
    "    Loads the rfs for a network and performs some initial quality filtering\n",
    "    Returns a stream for the network that has been trimmed and moveout corrected\n",
    "    \"\"\"\n",
    "    network_dir = os.path.join(dataroot, f\"{network}-analysis\")\n",
    "    try:\n",
    "        latest_run = max(\n",
    "            [\n",
    "                os.path.join(network_dir, d)\n",
    "                for d in os.listdir(network_dir)\n",
    "                if os.path.isdir(os.path.join(network_dir, d)) and d != \"corrections\"\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # print(f\"No run found for network {net}.\")\n",
    "        return (network, 0, 0)\n",
    "\n",
    "    # Grab the latest .h5 file - should be the outputs of qc\n",
    "    try:\n",
    "        h5_file = max(\n",
    "            [\n",
    "                os.path.join(latest_run, f)\n",
    "                for f in os.listdir(latest_run)\n",
    "                if os.path.splitext(f)[1] == \".h5\"\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # print(f\"No run found for network {net}.\")\n",
    "        return (network, 0, 0)\n",
    "\n",
    "    try:\n",
    "        stream = rf.read_rf(h5_file, format=\"h5\")\n",
    "    except:\n",
    "        # print(f\"Something went wrong when reading {h5_file}. Moving on...\")\n",
    "        return (network, 0, 0)\n",
    "    # Drop transverse component\n",
    "    stream = stream.select(channel=\"??R\")\n",
    "\n",
    "    # Trim to a reasonable time length\n",
    "    starttime = -5\n",
    "    endtime = 10\n",
    "    stream = stream.trim2(starttime, endtime, reftime=\"onset\")\n",
    "\n",
    "    stream.moveout()\n",
    "\n",
    "    # Count initial number of stations and traces\n",
    "    nstations = len(set([trace.stats.station for trace in stream]))\n",
    "    ntraces = len(stream)\n",
    "\n",
    "    # Apply quality filter\n",
    "    stream = quality_filter(stream)\n",
    "    if len(stream) == 0:\n",
    "        # print(f\"Nothing left after quality control for network {net}. Moving on...\")\n",
    "        return (network, 0, 0)\n",
    "\n",
    "    return (stream, nstations, ntraces)\n",
    "\n",
    "\n",
    "def get_station_stack_delays(stream: rf.RFStream):\n",
    "    # Station dictionary\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "\n",
    "    # stack stations individually, otherwise station coordinates also get stacked\n",
    "    stacks = rf.RFStream()\n",
    "    for v in rf_station_dict.values():\n",
    "        stacks += _stack(v)\n",
    "\n",
    "    # Get delay of each stack\n",
    "    for stack in stacks:\n",
    "        delay = peak_delay(stack)\n",
    "        if delay >= 0:\n",
    "            stack.stats[\"delay\"] = delay\n",
    "        else:\n",
    "            print(f\"Negative delay obtained for {stack.stats.network}.{stack.stats.station}\")\n",
    "            stacks.remove(stack)\n",
    "\n",
    "    return stacks.sort([\"delay\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "534a2e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Parallel(n_jobs=-1)(delayed(load_network_rfs)(net) for net in networks)\n",
    "rfstream = rf.RFStream()  # Stream with every RF\n",
    "init_nstations = {}\n",
    "init_ntraces = {}\n",
    "for res in result:\n",
    "    _netstream, _nstations, _ntraces = res\n",
    "    if isinstance(_netstream, rf.RFStream):\n",
    "        net = _netstream[0].stats.network\n",
    "        rfstream += _netstream\n",
    "    elif isinstance(_netstream, str):\n",
    "        net = _netstream\n",
    "    init_nstations[net] = _nstations\n",
    "    init_ntraces[net] = _ntraces\n",
    "del result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60cdec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove traces with exceedingly large amplitudes that will dominate the stacks\n",
    "log10_amp_max = np.array([tr.stats.log10_amp_max for tr in rfstream])\n",
    "mean = np.mean(log10_amp_max)\n",
    "stddev = np.std(log10_amp_max)\n",
    "normed = (log10_amp_max - mean) / stddev\n",
    "amplitude_threshold = 4  # in units of stddev\n",
    "indices = np.where(np.abs(normed) <= amplitude_threshold)[0]\n",
    "rfstream = rf.RFStream(map(rfstream.__getitem__, indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c3af5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7E: 3/6 stations kept after quality control\n",
      "7E: 30/65 radial RFs kept after quality control\n",
      "7D: 6/7 stations kept after quality control\n",
      "7D: 84/120 radial RFs kept after quality control\n",
      "1Q: 78/87 stations kept after quality control\n",
      "1Q: 4107/5624 radial RFs kept after quality control\n",
      "1P: 22/24 stations kept after quality control\n",
      "1P: 1425/2243 radial RFs kept after quality control\n",
      "4J: 48/52 stations kept after quality control\n",
      "4J: 2826/4294 radial RFs kept after quality control\n",
      "3G: 62/65 stations kept after quality control\n",
      "3G: 3706/4628 radial RFs kept after quality control\n",
      "S1: 16/43 stations kept after quality control\n",
      "S1: 372/701 radial RFs kept after quality control\n",
      "6C: 16/16 stations kept after quality control\n",
      "6C: 770/1028 radial RFs kept after quality control\n",
      "1E: 16/16 stations kept after quality control\n",
      "1E: 618/814 radial RFs kept after quality control\n",
      "ZR: 51/52 stations kept after quality control\n",
      "ZR: 3577/4410 radial RFs kept after quality control\n",
      "5G: 39/40 stations kept after quality control\n",
      "5G: 7682/10129 radial RFs kept after quality control\n",
      "5J: 9/10 stations kept after quality control\n",
      "5J: 472/663 radial RFs kept after quality control\n",
      "1H: 52/52 stations kept after quality control\n",
      "1H: 3154/3669 radial RFs kept after quality control\n",
      "8J: 90/98 stations kept after quality control\n",
      "8J: 3288/4567 radial RFs kept after quality control\n",
      "8K: 27/29 stations kept after quality control\n",
      "8K: 1229/1689 radial RFs kept after quality control\n",
      "7B: 27/36 stations kept after quality control\n",
      "7B: 693/893 radial RFs kept after quality control\n",
      "7H: 10/16 stations kept after quality control\n",
      "7H: 225/407 radial RFs kept after quality control\n",
      "7I: 22/24 stations kept after quality control\n",
      "7I: 1845/2935 radial RFs kept after quality control\n",
      "IU: 18/50 stations kept after quality control\n",
      "IU: 336/689 radial RFs kept after quality control\n",
      "OA: 232/233 stations kept after quality control\n",
      "OA: 22318/27286 radial RFs kept after quality control\n",
      "6K: 37/38 stations kept after quality control\n",
      "6K: 5363/6639 radial RFs kept after quality control\n",
      "AU: 89/94 stations kept after quality control\n",
      "AU: 6206/8122 radial RFs kept after quality control\n",
      "1F: 31/34 stations kept after quality control\n",
      "1F: 1750/2166 radial RFs kept after quality control\n",
      "1G: 35/41 stations kept after quality control\n",
      "1G: 1911/2315 radial RFs kept after quality control\n",
      "7S: 39/41 stations kept after quality control\n",
      "7S: 1610/1964 radial RFs kept after quality control\n",
      "7L: 42/44 stations kept after quality control\n",
      "7L: 1674/2057 radial RFs kept after quality control\n",
      "7M: 66/79 stations kept after quality control\n",
      "7M: 5070/6647 radial RFs kept after quality control\n",
      "7F: 7/15 stations kept after quality control\n",
      "7F: 104/221 radial RFs kept after quality control\n",
      "7G: 20/24 stations kept after quality control\n",
      "7G: 709/1031 radial RFs kept after quality control\n",
      "3O: 8/8 stations kept after quality control\n",
      "3O: 418/546 radial RFs kept after quality control\n",
      "4H: 44/44 stations kept after quality control\n",
      "4H: 3291/3932 radial RFs kept after quality control\n",
      "7K: 20/20 stations kept after quality control\n",
      "7K: 1108/1588 radial RFs kept after quality control\n",
      "7J: 24/25 stations kept after quality control\n",
      "7J: 1444/2154 radial RFs kept after quality control\n",
      "5C: 1/31 stations kept after quality control\n",
      "5C: 10/291 radial RFs kept after quality control\n",
      "1K: 61/69 stations kept after quality control\n",
      "1K: 4036/5150 radial RFs kept after quality control\n",
      "II: 16/35 stations kept after quality control\n",
      "II: 452/714 radial RFs kept after quality control\n",
      "6F: 24/25 stations kept after quality control\n",
      "6F: 3629/5081 radial RFs kept after quality control\n",
      "7U: 55/55 stations kept after quality control\n",
      "7U: 4419/5101 radial RFs kept after quality control\n",
      "7T: 31/31 stations kept after quality control\n",
      "7T: 1692/2430 radial RFs kept after quality control\n"
     ]
    }
   ],
   "source": [
    "# Count remaining stations and traces\n",
    "for net in networks:\n",
    "    stream = rfstream.select(network=net)\n",
    "    nstations = len(set([trace.stats.station for trace in stream]))\n",
    "    ntraces = len(stream)\n",
    "    print(f\"{net}: {nstations}/{init_nstations[net]} stations kept after quality control\")\n",
    "    print(f\"{net}: {ntraces}/{init_ntraces[net]} radial RFs kept after quality control\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6b777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstacks = rf.RFStream()  # Stream with station stacks\n",
    "for net in networks:\n",
    "    rfstacks += get_station_stack_delays(rfstream.select(network=net))\n",
    "rfstacks = rfstacks.sort([\"delay\", \"network\", \"station\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ef1750",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable function object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/auggiemarignier/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"/Users/auggiemarignier/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/auggiemarignier/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/auggiemarignier/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/auggiemarignier/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/parallel.py\", line 289, in <listcomp>\n    for func, args, kwargs in self.items]\nTypeError: cannot unpack non-iterable function object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 44\u001b[0m\n\u001b[1;32m     40\u001b[0m     plot_map(stacks, outdir)\n\u001b[1;32m     43\u001b[0m \u001b[39m# Plots for each network\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)(\n\u001b[1;32m     45\u001b[0m     delayed(plot_rfs_stacks_map)(\n\u001b[1;32m     46\u001b[0m         net, rfstream\u001b[39m.\u001b[39;49mselect(network\u001b[39m=\u001b[39;49mnet), rfstacks\u001b[39m.\u001b[39;49mselect(network\u001b[39m=\u001b[39;49mnet)\n\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[39m# Plot the full map\u001b[39;00m\n\u001b[1;32m     50\u001b[0m outdir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(processedroot, now)\n",
      "File \u001b[0;32m~/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/aussedthick/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniforge3/envs/aussedthick/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable function object"
     ]
    }
   ],
   "source": [
    "dry_run = False\n",
    "if not dry_run:\n",
    "    # Make output directories\n",
    "    now = (datetime.now()).strftime(format=\"%Y%m%d_%H%M%S\")\n",
    "    processedroot = os.path.join(dataroot, \"processed\")\n",
    "    for net in networks:\n",
    "        os.makedirs(os.path.join(processedroot, now, net))\n",
    "\n",
    "\n",
    "    def plot_rfs_stacks_map(network, stream, stacks):\n",
    "        outdir = os.path.join(processedroot, now, network)\n",
    "        stations = set([stack.stats.station for stack in stacks])\n",
    "        # plot RFs at each station\n",
    "        for station, rfs in zip(stations, stream.select(station=station)):\n",
    "            plot_name = os.path.join(outdir, f\"{station}.pdf\")\n",
    "            fig = rfs.plot_rf(\n",
    "                fname=plot_name,\n",
    "                fig_width=4,\n",
    "                fillcolors=(\"green\", None),\n",
    "                trace_height=0.1,\n",
    "                scale=3,\n",
    "                show_vlines=True,\n",
    "                trim=(-2, 6),\n",
    "            )  # this figure needs some bits to be moved around\n",
    "\n",
    "        # Plot the stacked RFs of the network\n",
    "        plot_name = os.path.join(outdir, f\"stacks.pdf\")\n",
    "        fig = stacks.plot_rf(\n",
    "            fname=plot_name,\n",
    "            fig_width=4,\n",
    "            fillcolors=(\"green\", None),\n",
    "            trace_height=0.1,\n",
    "            scale=3,\n",
    "            show_vlines=True,\n",
    "            trim=(-2, 6),\n",
    "            info=(),\n",
    "        )  # customise this plot to use a colourmap\n",
    "\n",
    "        # Plot map of network delay times\n",
    "        plot_map(stacks, outdir)\n",
    "\n",
    "\n",
    "    # Plots for each network\n",
    "    Parallel(n_jobs=-1)(\n",
    "        delayed(plot_rfs_stacks_map)(\n",
    "            net, rfstream.select(network=net), rfstacks.select(network=net)\n",
    "        ) for net in networks\n",
    "    )\n",
    "    # Plot the full map\n",
    "    outdir = os.path.join(processedroot, now)\n",
    "    plot_map(rfstacks, outdir, show=True)\n",
    "\n",
    "    # Save the delay times in txt file\n",
    "    with open(os.path.join(outdir, \"delays.txt\"), \"w\") as f:\n",
    "        for stack in rfstacks:\n",
    "            f.write(\n",
    "                f\"{stack.meta.network:4}\\t{stack.meta.station:6}\\t{stack.meta.station_longitude}\\t{stack.meta.station_latitude}\\t{stack.stats.delay:.3f}\\n\"\n",
    "            )\n",
    "\n",
    "    # Save the final RFs and stacks\n",
    "    rfstream.write(os.path.join(outdir, \"rfstream.h5\"), format=\"H5\")\n",
    "    rfstacks.write(os.path.join(outdir, \"rfstacks.h5\"), format=\"H5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aussedthick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
