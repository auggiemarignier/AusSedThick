{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc03c0d6-4f72-493f-bb89-3ed8f1ca3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.core import UTCDateTime\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import pygmt\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2a07b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_delay(trace: rf.rfstream.RFTrace) -> float:\n",
    "    return trace.times()[np.argmax(trace.data)] - (\n",
    "        trace.stats.onset - trace.stats.starttime\n",
    "    )\n",
    "\n",
    "\n",
    "def quality_filter(stream: rf.RFStream) -> rf.RFStream:\n",
    "    \"\"\" \"\n",
    "    Applies various final quality controlls to the RFs\n",
    "    starttime and end time are in seconds relative to onset\n",
    "    \"\"\"\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        # Only keep traces where largest arrival is positive\n",
    "        if trace[np.argmax(np.abs(trace.data))] < 0:\n",
    "            continue\n",
    "        # Only keep traces where largest arrival is within 2 seconds\n",
    "        if peak_delay(trace) > 2:\n",
    "            continue\n",
    "        # Only keep traces with slope_ratio > 5\n",
    "        if trace.stats.slope_ratio < 5:\n",
    "            continue\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "\n",
    "    # Only keep stations with 10 or more traces\n",
    "    rf_station_dict = {\n",
    "        k: v.sort([\"back_azimuth\"]) for k, v in rf_station_dict.items() if len(v) >= 10\n",
    "    }\n",
    "\n",
    "    return sum(rf_station_dict.values(), start=rf.RFStream())\n",
    "\n",
    "\n",
    "def plot_map(stream: rf.RFStream, save_dir=\".\"):\n",
    "    region = [112, 155, -46, -8]\n",
    "    ln_min, ln_max, lt_min, lt_max = region\n",
    "    projection = (\n",
    "        f\"M{int(np.mean([ln_min, ln_max]))}/{int(np.mean([lt_min, lt_max]))}/15c\"\n",
    "    )\n",
    "\n",
    "    lats = np.zeros(len(stream), dtype=float)\n",
    "    lons = np.zeros_like(lats, dtype=float)\n",
    "    nets = np.zeros_like(lats, dtype=str)\n",
    "    delays = np.zeros_like(lats, dtype=float)\n",
    "\n",
    "    for i, trace in enumerate(stream):\n",
    "        lats[i] = trace.meta.station_latitude\n",
    "        lons[i] = trace.meta.station_longitude\n",
    "        nets[i] = trace.meta.network\n",
    "        delays[i] = trace.stats.delay\n",
    "\n",
    "    fig = pygmt.Figure()\n",
    "    fig.basemap(region=region, projection=projection, frame=True)\n",
    "    fig.coast(\n",
    "        region=region,\n",
    "        projection=projection,\n",
    "        shorelines=1,\n",
    "        land=\"#ffffe6\",\n",
    "        water=\"#e6ffff\",\n",
    "        borders=\"2/1p,grey\",\n",
    "    )\n",
    "\n",
    "    pygmt.makecpt(cmap=\"dem3\", series=[0, 2])\n",
    "\n",
    "    fig.plot(\n",
    "        region=region,\n",
    "        projection=projection,\n",
    "        x=lons,\n",
    "        y=lats,\n",
    "        style=f\"tc\",\n",
    "        pen=\"1p\",\n",
    "        fill=delays,\n",
    "        cmap=True,\n",
    "        size=np.full_like(lons, 0.3),\n",
    "    )\n",
    "    fig.colorbar(region=region, projection=projection, frame=\"af+lDelay Time TPsb (s)\")\n",
    "    if save_dir is not None:\n",
    "        mapfile = os.path.join(save_dir, \"delay_map.pdf\")\n",
    "        fig.savefig(mapfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86d2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of networks for which we have RFs\n",
    "try:\n",
    "    dataroot = os.environ[\"DATADIR\"]\n",
    "except KeyError:\n",
    "    dataroot = \"rf_data\"\n",
    "networks = [\n",
    "    net[:2]\n",
    "    for net in os.listdir(dataroot)\n",
    "    if len(net.split(\"-\")[0]) == 2 and net.split(\"-\")[1] == \"analysis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd9ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = True\n",
    "# Make output directories\n",
    "if not dry_run:\n",
    "    now = (datetime.now()).strftime(format=\"%Y%m%d_%H%M%S\")\n",
    "    processedroot = os.path.join(dataroot, \"processed\")\n",
    "    for net in networks:\n",
    "        os.makedirs(os.path.join(processedroot, now, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237c5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(network: str):\n",
    "    network_dir = os.path.join(dataroot, f\"{network}-analysis\")\n",
    "    outdir = os.path.join(processedroot, now, network) if not dry_run else None\n",
    "    try:\n",
    "        latest_run = max(\n",
    "            [\n",
    "                os.path.join(network_dir, d)\n",
    "                for d in os.listdir(network_dir)\n",
    "                if os.path.isdir(os.path.join(network_dir, d))\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # print(f\"No run found for network {net}.\")\n",
    "        return (None, None)\n",
    "    \n",
    "    # Grab the latest .h5 file - should be the outputs of qc\n",
    "    try:\n",
    "        h5_file = max(\n",
    "            [\n",
    "                os.path.join(latest_run, f)\n",
    "                for f in os.listdir(latest_run)\n",
    "                if os.path.splitext(f)[1] == \".h5\"\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # print(f\"No run found for network {net}.\")\n",
    "        return (None, None)\n",
    "    \n",
    "    try:\n",
    "        stream = rf.read_rf(h5_file, format='h5')\n",
    "    except:\n",
    "        # print(f\"Something went wrong when reading {h5_file}. Moving on...\")\n",
    "        return (None, None)\n",
    "    # Drop transverse component\n",
    "    stream = stream.select(channel=\"??R\")\n",
    "    # Trim to a reasonable time length\n",
    "    starttime = -5\n",
    "    endtime = 10\n",
    "    stream = stream.trim2(starttime, endtime, reftime=\"onset\")\n",
    "\n",
    "    stream.moveout()\n",
    "    \n",
    "    # Count initial number of stations and traces\n",
    "    nstations = len(set([trace.stats.station for trace in stream]))\n",
    "    ntraces = len(stream)\n",
    "\n",
    "    # Apply quality filter\n",
    "    stream = quality_filter(stream)\n",
    "    if len(stream) == 0:\n",
    "        # print(f\"Nothing left after quality control for network {net}. Moving on...\")\n",
    "        return (None, None)\n",
    "\n",
    "    # Station dictionary\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "    \n",
    "    # stack stations individually, otherwise station coordinates also get stacked\n",
    "    stacks = rf.RFStream()\n",
    "    for v in rf_station_dict.values():\n",
    "        _v = v.copy()\n",
    "        # RFStream.stack() forces stacking for separate ids, including channels\n",
    "        # Access original obspy Stream.stack() to stack BHR and HHR channels\n",
    "        stacks += super(rf.RFStream, _v).stack(group_by=\"{network}.{station}\")\n",
    "\n",
    "    # Get delay of each stack\n",
    "    for trace in stacks:\n",
    "        trace.stats[\"delay\"] = peak_delay(trace)\n",
    "    stacks = stacks.sort([\"delay\"])\n",
    "\n",
    "    if not dry_run:\n",
    "        # plot RFs at each station\n",
    "        for k, v in rf_station_dict.items():\n",
    "            plot_name = os.path.join(outdir, f\"{k}.pdf\")\n",
    "            fig = v.plot_rf(fname=plot_name,\n",
    "                fig_width=4,\n",
    "                fillcolors=(\"green\", None),\n",
    "                trace_height=0.1,\n",
    "                scale=3,\n",
    "                show_vlines=True,\n",
    "                trim=(-2, 6),\n",
    "            )  # this figure needs some bits to be moved around\n",
    "\n",
    "        # Plot the stacked RFs of the network\n",
    "        plot_name = os.path.join(outdir, f\"stacks.pdf\")\n",
    "        fig = stacks.plot_rf(fname=plot_name,\n",
    "            fig_width=4,\n",
    "            fillcolors=(\"green\", None),\n",
    "            trace_height=0.1,\n",
    "            scale=3,\n",
    "            show_vlines=True,\n",
    "            trim=(-2, 6),\n",
    "            info=(),\n",
    "        ) # customise this plot to use a colourmap\n",
    "\n",
    "        # Plot map of network delay times\n",
    "        plot_map(stacks, outdir)\n",
    "\n",
    "    print(\n",
    "        f\"{network}: {len(stacks)}/{nstations} stations kept after quality control\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{network}: {len(stream)}/{ntraces} radial RFs kept after quality control\"\n",
    "    )\n",
    "\n",
    "    return (stream, stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c2e9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1: 67/45 stations kept after quality control\n",
      "S1: 2294/2322 radial RFs kept after quality control\n"
     ]
    }
   ],
   "source": [
    "result = Parallel(n_jobs=-1)(delayed(task)(net) for net in networks)  # This doesn't seem to be working in parallel properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstream = rf.RFStream()  # Stream with every RF\n",
    "rfstacks = rf.RFStream()  # Stream with station stacks\n",
    "for res in result:\n",
    "    stream, stacks = res\n",
    "    if stream is not None:\n",
    "        rfstream += stream\n",
    "    if stacks is not None:\n",
    "        rfstacks += stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ef1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dry_run:\n",
    "    # Plot the full map\n",
    "    outdir = os.path.join(processedroot, now)\n",
    "    plot_map(rfstacks, outdir)\n",
    "\n",
    "    # Save the delay times in txt file\n",
    "    with open(os.path.join(outdir, \"delays.txt\"), \"w\") as f:\n",
    "        for stack in rfstacks:\n",
    "            f.write(f\"{stack.meta.network:4}\\t{stack.meta.station:6}\\t{stack.meta.station_longitude}\\t{stack.meta.station_latitude}\\t{stack.stats.delay:.3f}\\n\")\n",
    "\n",
    "    # Save the final RFs and stacks\n",
    "    rfstream.write(os.path.join(outdir, \"rfstream.h5\"), format=\"H5\")\n",
    "    rfstacks.write(os.path.join(outdir, \"rfstacks.h5\"), format=\"H5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56978613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aussedthick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
