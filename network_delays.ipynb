{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f49661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONWARNINGS=ignore\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONWARNINGS=ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc03c0d6-4f72-493f-bb89-3ed8f1ca3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.core import UTCDateTime\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import pygmt\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a07b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_delay(trace: rf.rfstream.RFTrace) -> float:\n",
    "    return trace.times()[np.argmax(trace.data)] - (\n",
    "        trace.stats.onset - trace.stats.starttime\n",
    "    )\n",
    "\n",
    "\n",
    "def _stack(stream: rf.RFStream) -> rf.RFStream():\n",
    "    \"\"\"\n",
    "    TO BE USED ONLY WHEN STREAM ONLY CONTAINS TRACES FROM THE SAME STATION\n",
    "    RFStream.stack() forces stacking for separate ids, including channels\n",
    "    Access original obspy Stream.stack() to stack BHR and HHR channels\n",
    "    Copies meta data as in RFStream.stack()\n",
    "    \"\"\"\n",
    "    _stream = stream.copy()  # Stream.stack() operates in place\n",
    "    stack = super(rf.RFStream, _stream).stack(group_by=\"{network}.{station}\")\n",
    "    assert len(stack) == 1\n",
    "    tr = stream[0]\n",
    "    data = stack[0].data\n",
    "    header = {}\n",
    "    for entry in (\n",
    "        \"network\",\n",
    "        \"station\",\n",
    "        \"sampling_rate\",\n",
    "        \"phase\",\n",
    "        \"moveout\",\n",
    "        \"station_latitude\",\n",
    "        \"station_longitude\",\n",
    "        \"station_elevation\",\n",
    "        \"processing\",\n",
    "    ):\n",
    "        if entry in tr.stats:\n",
    "            header[entry] = tr.stats[entry]\n",
    "    _tr = rf.rfstream.RFTrace(data=data, header=header)\n",
    "    if \"onset\" in tr.stats:\n",
    "        onset = tr.stats.onset - tr.stats.starttime\n",
    "        _tr.stats.onset = _tr.stats.starttime + onset\n",
    "    return rf.RFStream(_tr)\n",
    "\n",
    "\n",
    "def quality_filter(stream: rf.RFStream) -> rf.RFStream:\n",
    "    \"\"\" \"\n",
    "    Applies various final quality controlls to the RFs\n",
    "    starttime and end time are in seconds relative to onset\n",
    "    \"\"\"\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        # Only keep traces where largest arrival is positive\n",
    "        if trace[np.argmax(np.abs(trace.data))] < 0:\n",
    "            continue\n",
    "        # Only keep traces where largest arrival is within 2 seconds\n",
    "        if peak_delay(trace) > 2:\n",
    "            continue\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "\n",
    "    # Only keep stations with 10 or more traces\n",
    "    rf_station_dict = {\n",
    "        k: v.sort([\"back_azimuth\"]) for k, v in rf_station_dict.items() if len(v) >= 10\n",
    "    }\n",
    "\n",
    "    return sum(rf_station_dict.values(), start=rf.RFStream())\n",
    "\n",
    "\n",
    "def plot_map(stream: rf.RFStream, save_dir=\".\", show=False):\n",
    "    region = [112, 155, -46, -8]\n",
    "    ln_min, ln_max, lt_min, lt_max = region\n",
    "    projection = (\n",
    "        f\"M{int(np.mean([ln_min, ln_max]))}/{int(np.mean([lt_min, lt_max]))}/15c\"\n",
    "    )\n",
    "\n",
    "    lats = np.zeros(len(stream), dtype=float)\n",
    "    lons = np.zeros_like(lats, dtype=float)\n",
    "    nets = np.zeros_like(lats, dtype=str)\n",
    "    delays = np.zeros_like(lats, dtype=float)\n",
    "\n",
    "    for i, trace in enumerate(stream):\n",
    "        lats[i] = trace.meta.station_latitude\n",
    "        lons[i] = trace.meta.station_longitude\n",
    "        nets[i] = trace.meta.network\n",
    "        delays[i] = trace.stats.delay\n",
    "\n",
    "    fig = pygmt.Figure()\n",
    "    fig.basemap(region=region, projection=projection, frame=True)\n",
    "    fig.coast(\n",
    "        region=region,\n",
    "        projection=projection,\n",
    "        shorelines=1,\n",
    "        land=\"#ffffe6\",\n",
    "        water=\"#e6ffff\",\n",
    "        borders=\"2/1p,grey\",\n",
    "    )\n",
    "\n",
    "    pygmt.makecpt(cmap=\"plasma\", truncate=[0.2, 1], series=[0, 2])\n",
    "\n",
    "    fig.plot(\n",
    "        region=region,\n",
    "        projection=projection,\n",
    "        x=lons,\n",
    "        y=lats,\n",
    "        style=f\"tc\",\n",
    "        pen=\"1p\",\n",
    "        fill=delays,\n",
    "        cmap=True,\n",
    "        size=np.full_like(lons, 0.3),\n",
    "    )\n",
    "    fig.colorbar(region=region, projection=projection, frame=\"af+lDelay Time TPsb (s)\")\n",
    "    if save_dir is not None:\n",
    "        mapfile = os.path.join(save_dir, \"delay_map.pdf\")\n",
    "        fig.savefig(mapfile)\n",
    "    if show:\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86d2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of networks for which we have RFs\n",
    "try:\n",
    "    dataroot = os.environ[\"DATADIR\"]\n",
    "except KeyError:\n",
    "    dataroot = \"rf_data\"\n",
    "networks = [\n",
    "    net[:2]\n",
    "    for net in os.listdir(dataroot)\n",
    "    if len(net.split(\"-\")[0]) == 2 and net.split(\"-\")[1] == \"analysis\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237c5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network_rfs(network: str):\n",
    "    \"\"\"\n",
    "    Loads the rfs for a network and performs some initial quality filtering\n",
    "    Returns a stream for the network that has been trimmed and moveout corrected\n",
    "    \"\"\"\n",
    "    network_dir = os.path.join(dataroot, f\"{network}-analysis\")\n",
    "    try:\n",
    "        latest_run = max(\n",
    "            [\n",
    "                os.path.join(network_dir, d)\n",
    "                for d in os.listdir(network_dir)\n",
    "                if os.path.isdir(os.path.join(network_dir, d))\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # print(f\"No run found for network {net}.\")\n",
    "        return (None, None, None)\n",
    "\n",
    "    # Grab the latest .h5 file - should be the outputs of qc\n",
    "    try:\n",
    "        h5_file = max(\n",
    "            [\n",
    "                os.path.join(latest_run, f)\n",
    "                for f in os.listdir(latest_run)\n",
    "                if os.path.splitext(f)[1] == \".h5\"\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # print(f\"No run found for network {net}.\")\n",
    "        return (None, None, None)\n",
    "\n",
    "    try:\n",
    "        stream = rf.read_rf(h5_file, format=\"h5\")\n",
    "    except:\n",
    "        # print(f\"Something went wrong when reading {h5_file}. Moving on...\")\n",
    "        return (None, None, None)\n",
    "    # Drop transverse component\n",
    "    stream = stream.select(channel=\"??R\")\n",
    "\n",
    "    # AU: drop stations not on continent or Tassie\n",
    "    if network == \"AU\":\n",
    "        stream = rf.RFStream(\n",
    "            [\n",
    "                tr\n",
    "                for tr in stream\n",
    "                if tr.stats.station\n",
    "                not in [\"XMIS\", \"MANU\", \"RABL\", \"NFK\", \"LHI\", \"MCQ\", \"NIUE\", \"MAW\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Trim to a reasonable time length\n",
    "    starttime = -5\n",
    "    endtime = 10\n",
    "    stream = stream.trim2(starttime, endtime, reftime=\"onset\")\n",
    "\n",
    "    stream.moveout()\n",
    "\n",
    "    # Count initial number of stations and traces\n",
    "    nstations = len(set([trace.stats.station for trace in stream]))\n",
    "    ntraces = len(stream)\n",
    "\n",
    "    # Apply quality filter\n",
    "    stream = quality_filter(stream)\n",
    "    if len(stream) == 0:\n",
    "        # print(f\"Nothing left after quality control for network {net}. Moving on...\")\n",
    "        return (None, None, None)\n",
    "\n",
    "    return (stream, nstations, ntraces)\n",
    "\n",
    "\n",
    "def get_station_stack_delays(stream: rf.RFStream):\n",
    "    # Station dictionary\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "\n",
    "    # stack stations individually, otherwise station coordinates also get stacked\n",
    "    stacks = rf.RFStream()\n",
    "    for v in rf_station_dict.values():\n",
    "        stacks += _stack(v)\n",
    "\n",
    "    # Get delay of each stack\n",
    "    for stack in stacks:\n",
    "        stack.stats[\"delay\"] = peak_delay(stack)\n",
    "\n",
    "    return stacks.sort([\"delay\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "534a2e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Parallel(n_jobs=-1)(delayed(load_network_rfs)(net) for net in networks)\n",
    "rfstream = rf.RFStream()\n",
    "init_nstations = []\n",
    "init_ntraces = []\n",
    "for res in result:\n",
    "    rfstream += res[0]  # Stream with every RF\n",
    "    init_nstations.append(res[1])\n",
    "    init_ntraces.append(res[2])\n",
    "del result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60cdec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove traces with exceedingly large amplitudes that will dominate the stacks\n",
    "log10_amp_max = np.array([tr.stats.log10_amp_max for tr in rfstream])\n",
    "mean = np.mean(log10_amp_max)\n",
    "stddev = np.std(log10_amp_max)\n",
    "normed = (log10_amp_max - mean) / stddev\n",
    "amplitude_threshold = 4  # in units of stddev\n",
    "indices = np.where(np.abs(normed) <= amplitude_threshold)[0]\n",
    "rfstream = rf.RFStream(map(rfstream.__getitem__, indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c3af5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7E: 3/6 stations kept after quality control\n",
      "7E: 30/65 radial RFs kept after quality control\n",
      "7D: 6/7 stations kept after quality control\n",
      "7D: 92/120 radial RFs kept after quality control\n",
      "1Q: 78/87 stations kept after quality control\n",
      "1Q: 4229/5624 radial RFs kept after quality control\n",
      "1P: 22/24 stations kept after quality control\n",
      "1P: 1511/2243 radial RFs kept after quality control\n",
      "4J: 49/52 stations kept after quality control\n",
      "4J: 2850/4294 radial RFs kept after quality control\n",
      "3G: 62/65 stations kept after quality control\n",
      "3G: 3723/4628 radial RFs kept after quality control\n",
      "S1: 16/43 stations kept after quality control\n",
      "S1: 395/701 radial RFs kept after quality control\n",
      "6C: 16/16 stations kept after quality control\n",
      "6C: 804/1028 radial RFs kept after quality control\n",
      "1E: 16/16 stations kept after quality control\n",
      "1E: 618/814 radial RFs kept after quality control\n",
      "ZR: 52/52 stations kept after quality control\n",
      "ZR: 3698/4410 radial RFs kept after quality control\n",
      "5G: 39/40 stations kept after quality control\n",
      "5G: 7729/10129 radial RFs kept after quality control\n",
      "5J: 10/10 stations kept after quality control\n",
      "5J: 495/663 radial RFs kept after quality control\n",
      "1H: 52/52 stations kept after quality control\n",
      "1H: 3334/3669 radial RFs kept after quality control\n",
      "8J: 90/98 stations kept after quality control\n",
      "8J: 3386/4567 radial RFs kept after quality control\n",
      "8K: 27/29 stations kept after quality control\n",
      "8K: 1279/1689 radial RFs kept after quality control\n",
      "7B: 27/36 stations kept after quality control\n",
      "7B: 706/893 radial RFs kept after quality control\n",
      "7H: 12/16 stations kept after quality control\n",
      "7H: 264/407 radial RFs kept after quality control\n",
      "7I: 22/24 stations kept after quality control\n",
      "7I: 1957/2935 radial RFs kept after quality control\n",
      "IU: 20/50 stations kept after quality control\n",
      "IU: 374/689 radial RFs kept after quality control\n",
      "OA: 231/233 stations kept after quality control\n",
      "OA: 22753/27239 radial RFs kept after quality control\n",
      "6K: 37/38 stations kept after quality control\n",
      "6K: 5479/6639 radial RFs kept after quality control\n",
      "AU: 81/86 stations kept after quality control\n",
      "AU: 6292/7644 radial RFs kept after quality control\n",
      "1F: 31/34 stations kept after quality control\n",
      "1F: 1809/2166 radial RFs kept after quality control\n",
      "1G: 35/41 stations kept after quality control\n",
      "1G: 1957/2315 radial RFs kept after quality control\n",
      "7S: 39/41 stations kept after quality control\n",
      "7S: 1664/1964 radial RFs kept after quality control\n",
      "7L: 42/44 stations kept after quality control\n",
      "7L: 1778/2057 radial RFs kept after quality control\n",
      "7M: 66/79 stations kept after quality control\n",
      "7M: 5267/6647 radial RFs kept after quality control\n",
      "7F: 8/15 stations kept after quality control\n",
      "7F: 118/221 radial RFs kept after quality control\n",
      "7G: 21/24 stations kept after quality control\n",
      "7G: 750/1031 radial RFs kept after quality control\n",
      "3O: 8/8 stations kept after quality control\n",
      "3O: 465/546 radial RFs kept after quality control\n",
      "4H: 44/44 stations kept after quality control\n",
      "4H: 3329/3932 radial RFs kept after quality control\n",
      "7K: 20/20 stations kept after quality control\n",
      "7K: 1155/1588 radial RFs kept after quality control\n",
      "7J: 24/25 stations kept after quality control\n",
      "7J: 1514/2154 radial RFs kept after quality control\n",
      "5C: 1/31 stations kept after quality control\n",
      "5C: 10/291 radial RFs kept after quality control\n",
      "1K: 61/69 stations kept after quality control\n",
      "1K: 4250/5150 radial RFs kept after quality control\n",
      "II: 17/35 stations kept after quality control\n",
      "II: 490/714 radial RFs kept after quality control\n",
      "6F: 24/25 stations kept after quality control\n",
      "6F: 3787/5081 radial RFs kept after quality control\n",
      "7U: 55/55 stations kept after quality control\n",
      "7U: 4693/5101 radial RFs kept after quality control\n",
      "7T: 31/31 stations kept after quality control\n",
      "7T: 1698/2430 radial RFs kept after quality control\n"
     ]
    }
   ],
   "source": [
    "# Count remaining stations and traces\n",
    "for i, net in enumerate(networks):\n",
    "    stream = rfstream.select(network=net)\n",
    "    nstations = len(set([trace.stats.station for trace in stream]))\n",
    "    ntraces = len(stream)\n",
    "    print(f\"{net}: {nstations}/{init_nstations[i]} stations kept after quality control\")\n",
    "    print(f\"{net}: {ntraces}/{init_ntraces[i]} radial RFs kept after quality control\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a6b777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstacks = rf.RFStream()  # Stream with station stacks\n",
    "for net in networks:\n",
    "    rfstacks += get_station_stack_delays(rfstream.select(network=net))\n",
    "rfstacks = rfstacks.sort([\"delay\", \"network\", \"station\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01ef1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = False\n",
    "if not dry_run:\n",
    "    # Make output directories\n",
    "    now = (datetime.now()).strftime(format=\"%Y%m%d_%H%M%S\")\n",
    "    processedroot = os.path.join(dataroot, \"processed\")\n",
    "    for net in networks:\n",
    "        os.makedirs(os.path.join(processedroot, now, net))\n",
    "\n",
    "\n",
    "    def plot_rfs_stacks_map(network, stream, stacks):\n",
    "        outdir = os.path.join(processedroot, now, network)\n",
    "        stations = set([stack.stats.station for stack in stacks])\n",
    "        # plot RFs at each station\n",
    "        for station, rfs in zip(stations, stream.select(station=station)):\n",
    "            plot_name = os.path.join(outdir, f\"{station}.pdf\")\n",
    "            fig = rfs.plot_rf(\n",
    "                fname=plot_name,\n",
    "                fig_width=4,\n",
    "                fillcolors=(\"green\", None),\n",
    "                trace_height=0.1,\n",
    "                scale=3,\n",
    "                show_vlines=True,\n",
    "                trim=(-2, 6),\n",
    "            )  # this figure needs some bits to be moved around\n",
    "\n",
    "        # Plot the stacked RFs of the network\n",
    "        plot_name = os.path.join(outdir, f\"stacks.pdf\")\n",
    "        fig = stacks.plot_rf(\n",
    "            fname=plot_name,\n",
    "            fig_width=4,\n",
    "            fillcolors=(\"green\", None),\n",
    "            trace_height=0.1,\n",
    "            scale=3,\n",
    "            show_vlines=True,\n",
    "            trim=(-2, 6),\n",
    "            info=(),\n",
    "        )  # customise this plot to use a colourmap\n",
    "\n",
    "        # Plot map of network delay times\n",
    "        plot_map(stacks, outdir)\n",
    "\n",
    "\n",
    "    # Plots for each network\n",
    "    Parallel(n_jobs=-1)(\n",
    "        delayed(plot_rfs_stacks_map)(\n",
    "            net, rfstream.select(network=net), rfstacks.select(network=net)\n",
    "        )\n",
    "    )\n",
    "    # Plot the full map\n",
    "    outdir = os.path.join(processedroot, now)\n",
    "    plot_map(rfstacks, outdir, show=True)\n",
    "\n",
    "    # Save the delay times in txt file\n",
    "    with open(os.path.join(outdir, \"delays.txt\"), \"w\") as f:\n",
    "        for stack in rfstacks:\n",
    "            f.write(\n",
    "                f\"{stack.meta.network:4}\\t{stack.meta.station:6}\\t{stack.meta.station_longitude}\\t{stack.meta.station_latitude}\\t{stack.stats.delay:.3f}\\n\"\n",
    "            )\n",
    "\n",
    "    # Save the final RFs and stacks\n",
    "    rfstream.write(os.path.join(outdir, \"rfstream.h5\"), format=\"H5\")\n",
    "    rfstacks.write(os.path.join(outdir, \"rfstacks.h5\"), format=\"H5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aussedthick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
