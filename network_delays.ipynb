{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc03c0d6-4f72-493f-bb89-3ed8f1ca3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.core import UTCDateTime\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import pygmt\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a07b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_delay(trace: rf.rfstream.RFTrace) -> float:\n",
    "    return trace.times()[np.argmax(trace.data)] - (\n",
    "        trace.stats.onset - trace.stats.starttime\n",
    "    )\n",
    "\n",
    "\n",
    "def _stack(stream: rf.RFStream) -> rf.RFStream():\n",
    "    \"\"\"\n",
    "    TO BE USED ONLY WHEN STREAM ONLY CONTAINS TRACES FROM THE SAME STATION\n",
    "    RFStream.stack() forces stacking for separate ids, including channels\n",
    "    Access original obspy Stream.stack() to stack BHR and HHR channels\n",
    "    Copies meta data as in RFStream.stack()\n",
    "    \"\"\"\n",
    "    _stream = stream.copy()  # Stream.stack() operates in place\n",
    "    stack = super(rf.RFStream, _stream).stack(group_by=\"{network}.{station}\")\n",
    "    assert len(stack) == 1\n",
    "    tr = stream[0]\n",
    "    data = stack[0].data\n",
    "    header = {}\n",
    "    for entry in (\n",
    "        \"network\",\n",
    "        \"station\",\n",
    "        \"sampling_rate\",\n",
    "        \"phase\",\n",
    "        \"moveout\",\n",
    "        \"station_latitude\",\n",
    "        \"station_longitude\",\n",
    "        \"station_elevation\",\n",
    "        \"processing\",\n",
    "    ):\n",
    "        if entry in tr.stats:\n",
    "            header[entry] = tr.stats[entry]\n",
    "    _tr = rf.rfstream.RFTrace(data=data, header=header)\n",
    "    if 'onset' in tr.stats:\n",
    "        onset = tr.stats.onset - tr.stats.starttime\n",
    "        _tr.stats.onset = _tr.stats.starttime + onset\n",
    "    return rf.RFStream(_tr)\n",
    "\n",
    "\n",
    "\n",
    "def quality_filter(stream: rf.RFStream) -> rf.RFStream:\n",
    "    \"\"\" \"\n",
    "    Applies various final quality controlls to the RFs\n",
    "    starttime and end time are in seconds relative to onset\n",
    "    \"\"\"\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        # Only keep traces where largest arrival is positive\n",
    "        if trace[np.argmax(np.abs(trace.data))] < 0:\n",
    "            continue\n",
    "        # Only keep traces where largest arrival is within 2 seconds\n",
    "        if peak_delay(trace) > 2:\n",
    "            continue\n",
    "        # Only keep traces with slope_ratio > 5\n",
    "        if trace.stats.slope_ratio < 5:\n",
    "            continue\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "\n",
    "    # Only keep stations with 10 or more traces\n",
    "    rf_station_dict = {\n",
    "        k: v.sort([\"back_azimuth\"]) for k, v in rf_station_dict.items() if len(v) >= 10\n",
    "    }\n",
    "\n",
    "    return sum(rf_station_dict.values(), start=rf.RFStream())\n",
    "\n",
    "\n",
    "def plot_map(stream: rf.RFStream, save_dir=\".\"):\n",
    "    region = [112, 155, -46, -8]\n",
    "    ln_min, ln_max, lt_min, lt_max = region\n",
    "    projection = (\n",
    "        f\"M{int(np.mean([ln_min, ln_max]))}/{int(np.mean([lt_min, lt_max]))}/15c\"\n",
    "    )\n",
    "\n",
    "    lats = np.zeros(len(stream), dtype=float)\n",
    "    lons = np.zeros_like(lats, dtype=float)\n",
    "    nets = np.zeros_like(lats, dtype=str)\n",
    "    delays = np.zeros_like(lats, dtype=float)\n",
    "\n",
    "    for i, trace in enumerate(stream):\n",
    "        lats[i] = trace.meta.station_latitude\n",
    "        lons[i] = trace.meta.station_longitude\n",
    "        nets[i] = trace.meta.network\n",
    "        delays[i] = trace.stats.delay\n",
    "\n",
    "    fig = pygmt.Figure()\n",
    "    fig.basemap(region=region, projection=projection, frame=True)\n",
    "    fig.coast(\n",
    "        region=region,\n",
    "        projection=projection,\n",
    "        shorelines=1,\n",
    "        land=\"#ffffe6\",\n",
    "        water=\"#e6ffff\",\n",
    "        borders=\"2/1p,grey\",\n",
    "    )\n",
    "\n",
    "    pygmt.makecpt(cmap=\"dem3\", series=[0, 2])\n",
    "\n",
    "    fig.plot(\n",
    "        region=region,\n",
    "        projection=projection,\n",
    "        x=lons,\n",
    "        y=lats,\n",
    "        style=f\"tc\",\n",
    "        pen=\"1p\",\n",
    "        fill=delays,\n",
    "        cmap=True,\n",
    "        size=np.full_like(lons, 0.3),\n",
    "    )\n",
    "    fig.colorbar(region=region, projection=projection, frame=\"af+lDelay Time TPsb (s)\")\n",
    "    if save_dir is not None:\n",
    "        mapfile = os.path.join(save_dir, \"delay_map.pdf\")\n",
    "        fig.savefig(mapfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86d2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of networks for which we have RFs\n",
    "try:\n",
    "    dataroot = os.environ[\"DATADIR\"]\n",
    "except KeyError:\n",
    "    dataroot = \"rf_data\"\n",
    "networks = [\n",
    "    net[:2]\n",
    "    for net in os.listdir(dataroot)\n",
    "    if len(net.split(\"-\")[0]) == 2 and net.split(\"-\")[1] == \"analysis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd9ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = True\n",
    "# Make output directories\n",
    "if not dry_run:\n",
    "    now = (datetime.now()).strftime(format=\"%Y%m%d_%H%M%S\")\n",
    "    processedroot = os.path.join(dataroot, \"processed\")\n",
    "    for net in networks:\n",
    "        os.makedirs(os.path.join(processedroot, now, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "237c5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(network: str):\n",
    "    network_dir = os.path.join(dataroot, f\"{network}-analysis\")\n",
    "    outdir = os.path.join(processedroot, now, network) if not dry_run else None\n",
    "    try:\n",
    "        latest_run = max(\n",
    "            [\n",
    "                os.path.join(network_dir, d)\n",
    "                for d in os.listdir(network_dir)\n",
    "                if os.path.isdir(os.path.join(network_dir, d))\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # print(f\"No run found for network {net}.\")\n",
    "        return (None, None)\n",
    "    \n",
    "    # Grab the latest .h5 file - should be the outputs of qc\n",
    "    try:\n",
    "        h5_file = max(\n",
    "            [\n",
    "                os.path.join(latest_run, f)\n",
    "                for f in os.listdir(latest_run)\n",
    "                if os.path.splitext(f)[1] == \".h5\"\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # print(f\"No run found for network {net}.\")\n",
    "        return (None, None)\n",
    "    \n",
    "    try:\n",
    "        stream = rf.read_rf(h5_file, format='h5')\n",
    "    except:\n",
    "        # print(f\"Something went wrong when reading {h5_file}. Moving on...\")\n",
    "        return (None, None)\n",
    "    # Drop transverse component\n",
    "    stream = stream.select(channel=\"??R\")\n",
    "    # Trim to a reasonable time length\n",
    "    starttime = -5\n",
    "    endtime = 10\n",
    "    stream = stream.trim2(starttime, endtime, reftime=\"onset\")\n",
    "\n",
    "    stream.moveout()\n",
    "    \n",
    "    # Count initial number of stations and traces\n",
    "    nstations = len(set([trace.stats.station for trace in stream]))\n",
    "    ntraces = len(stream)\n",
    "\n",
    "    # Apply quality filter\n",
    "    stream = quality_filter(stream)\n",
    "    if len(stream) == 0:\n",
    "        # print(f\"Nothing left after quality control for network {net}. Moving on...\")\n",
    "        return (None, None)\n",
    "\n",
    "    # Station dictionary\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "    \n",
    "    # stack stations individually, otherwise station coordinates also get stacked\n",
    "    stacks = rf.RFStream()\n",
    "    for v in rf_station_dict.values():\n",
    "        stacks += _stack(v)\n",
    "\n",
    "    # Get delay of each stack\n",
    "    for trace in stacks:\n",
    "        trace.stats[\"delay\"] = peak_delay(trace)\n",
    "    stacks = stacks.sort([\"delay\"])\n",
    "\n",
    "    if not dry_run:\n",
    "        # plot RFs at each station\n",
    "        for k, v in rf_station_dict.items():\n",
    "            plot_name = os.path.join(outdir, f\"{k}.pdf\")\n",
    "            fig = v.plot_rf(fname=plot_name,\n",
    "                fig_width=4,\n",
    "                fillcolors=(\"green\", None),\n",
    "                trace_height=0.1,\n",
    "                scale=3,\n",
    "                show_vlines=True,\n",
    "                trim=(-2, 6),\n",
    "            )  # this figure needs some bits to be moved around\n",
    "\n",
    "        # Plot the stacked RFs of the network\n",
    "        plot_name = os.path.join(outdir, f\"stacks.pdf\")\n",
    "        fig = stacks.plot_rf(fname=plot_name,\n",
    "            fig_width=4,\n",
    "            fillcolors=(\"green\", None),\n",
    "            trace_height=0.1,\n",
    "            scale=3,\n",
    "            show_vlines=True,\n",
    "            trim=(-2, 6),\n",
    "            info=(),\n",
    "        ) # customise this plot to use a colourmap\n",
    "\n",
    "        # Plot map of network delay times\n",
    "        plot_map(stacks, outdir)\n",
    "\n",
    "    print(\n",
    "        f\"{network}: {len(stacks)}/{nstations} stations kept after quality control\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{network}: {len(stream)}/{ntraces} radial RFs kept after quality control\"\n",
    "    )\n",
    "\n",
    "    return (stream, stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c2e9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7D: 1/7 stations kept after quality control\n",
      "7D: 11/195 radial RFs kept after quality control\n",
      "S1: 1/45 stations kept after quality control\n",
      "S1: 35/2322 radial RFs kept after quality control\n",
      "1E: 15/16 stations kept after quality control\n",
      "1E: 290/2228 radial RFs kept after quality control\n",
      "6C: 13/16 stations kept after quality control\n",
      "6C: 204/2435 radial RFs kept after quality control\n",
      "5J: 9/10 stations kept after quality control\n",
      "5J: 237/1487 radial RFs kept after quality control\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)(delayed(task)(net) \u001b[39mfor\u001b[39;49;00m net \u001b[39min\u001b[39;49;00m networks)  \u001b[39m# This doesn't seem to be working in parallel properly\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniforge3/envs/aussedthick/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/aussedthick/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniforge3/envs/aussedthick/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = Parallel(n_jobs=-1)(delayed(task)(net) for net in networks)  # This doesn't seem to be working in parallel properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstream = rf.RFStream()  # Stream with every RF\n",
    "rfstacks = rf.RFStream()  # Stream with station stacks\n",
    "for res in result:\n",
    "    stream, stacks = res\n",
    "    if stream is not None:\n",
    "        rfstream += stream\n",
    "    if stacks is not None:\n",
    "        rfstacks += stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ef1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dry_run:\n",
    "    # Plot the full map\n",
    "    outdir = os.path.join(processedroot, now)\n",
    "    plot_map(rfstacks, outdir)\n",
    "\n",
    "    # Save the delay times in txt file\n",
    "    with open(os.path.join(outdir, \"delays.txt\"), \"w\") as f:\n",
    "        for stack in rfstacks:\n",
    "            f.write(f\"{stack.meta.network:4}\\t{stack.meta.station:6}\\t{stack.meta.station_longitude}\\t{stack.meta.station_latitude}\\t{stack.stats.delay:.3f}\\n\")\n",
    "\n",
    "    # Save the final RFs and stacks\n",
    "    rfstream.write(os.path.join(outdir, \"rfstream.h5\"), format=\"H5\")\n",
    "    rfstacks.write(os.path.join(outdir, \"rfstacks.h5\"), format=\"H5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56978613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aussedthick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
