{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Receiver Functions\n",
    "\n",
    "This notebook does the main processing of the measured receiver functions.\n",
    "The processing includes\n",
    "\n",
    "1. Quality filtering\n",
    "2. Measuring of $P$-to-$S$ sediment basement conversion delay time $t_{PS_b}$\n",
    "3. Measuring of the two-way travel-time of shear waves in the sediment layer $t_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.core import UTCDateTime\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import pygmt\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.signal import argrelmax\n",
    "\n",
    "from utils import australia_basemap\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RFs and QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataroot = os.environ[\"DATADIR\"]\n",
    "except KeyError:\n",
    "    dataroot = os.path.join(\"..\", \"data\",\"rf_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_filter(stream: rf.RFStream) -> rf.RFStream:\n",
    "    \"\"\"\n",
    "    Applies various final quality controls to the RFs\n",
    "    \"\"\"\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        # Only keep traces where largest arrival is positive\n",
    "        if trace[np.argmax(np.abs(trace.data))] < 0:\n",
    "            continue\n",
    "\n",
    "        # Only keep traces where largest arrival is within 2 seconds after direct P\n",
    "        largest_arrival = trace.times()[np.argmax(trace.data)] - (\n",
    "            trace.stats.onset - trace.stats.starttime\n",
    "        )\n",
    "        if largest_arrival > 2 or largest_arrival < 0:\n",
    "            continue\n",
    "\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "\n",
    "    # Only keep stations with 10 or more traces\n",
    "    rf_station_dict = {\n",
    "        k: v.sort([\"back_azimuth\"]) for k, v in rf_station_dict.items() if len(v) >= 10\n",
    "    }\n",
    "\n",
    "    return sum(rf_station_dict.values(), start=rf.RFStream())\n",
    "\n",
    "\n",
    "def load_network_rfs(network: str):\n",
    "    \"\"\"\n",
    "    Loads the rfs for a network and performs some initial quality filtering\n",
    "    Returns a stream for the network that has been trimmed and moveout corrected and a count of how many stations and traces were recorded BEFORE any quality control\n",
    "    \"\"\"\n",
    "    network_dir = os.path.join(dataroot, f\"{network}-analysis\")\n",
    "    try:\n",
    "        latest_run = max(\n",
    "            [\n",
    "                os.path.join(network_dir, d)\n",
    "                for d in os.listdir(network_dir)\n",
    "                if os.path.isdir(os.path.join(network_dir, d)) and d != \"corrections\"\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"No run found for network {network}.\")\n",
    "        return (network, 0, 0)\n",
    "\n",
    "    # Grab the latest .h5 file - should be the outputs of qc\n",
    "    try:\n",
    "        h5_file = max(\n",
    "            [\n",
    "                os.path.join(latest_run, f)\n",
    "                for f in os.listdir(latest_run)\n",
    "                if os.path.splitext(f)[1] == \".h5\"\n",
    "            ],\n",
    "            key=os.path.getmtime,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"No run found for network {network}.\")\n",
    "        return (network, 0, 0)\n",
    "\n",
    "    try:\n",
    "        stream = rf.read_rf(h5_file, format=\"h5\")\n",
    "    except:\n",
    "        print(f\"Something went wrong when reading {h5_file}. Moving on...\")\n",
    "        return (network, 0, 0)\n",
    "    # Drop transverse component\n",
    "    stream = stream.select(channel=\"??R\")\n",
    "\n",
    "    # Trim to a reasonable time length\n",
    "    starttime = -5\n",
    "    endtime = 10\n",
    "    stream = stream.trim2(starttime, endtime, reftime=\"onset\")\n",
    "\n",
    "    stream.moveout()\n",
    "\n",
    "    # Count initial number of stations and traces\n",
    "    nstations = len(set([trace.stats.station for trace in stream]))\n",
    "    ntraces = len(stream)\n",
    "\n",
    "    # Apply quality filter\n",
    "    stream = quality_filter(stream)\n",
    "    if len(stream) == 0:\n",
    "        print(f\"Nothing left after quality control for network {network}. Moving on...\")\n",
    "        return (network, nstations, ntraces)\n",
    "\n",
    "    return (stream, nstations, ntraces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the networks in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = [\n",
    "    net[:2]\n",
    "    for net in os.listdir(dataroot)\n",
    "    if len(net.split(\"-\")[0]) == 2 and net.split(\"-\")[1] == \"analysis\"\n",
    "]\n",
    "\n",
    "result = Parallel(n_jobs=-1)(delayed(load_network_rfs)(net) for net in networks)\n",
    "rfstream = rf.RFStream()  # Stream with every RF\n",
    "init_nstations = {}\n",
    "init_ntraces = {}\n",
    "for res in result:\n",
    "    _netstream, _nstations, _ntraces = res\n",
    "    if isinstance(_netstream, rf.RFStream):\n",
    "        net = _netstream[0].stats.network\n",
    "        rfstream += _netstream\n",
    "    elif isinstance(_netstream, str):\n",
    "        net = _netstream\n",
    "    init_nstations[net] = _nstations\n",
    "    init_ntraces[net] = _ntraces\n",
    "del result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove traces with exeedingly large amplitudes that will dominate the stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log10_amp_max = np.array([tr.stats.log10_amp_max for tr in rfstream])\n",
    "mean = np.mean(log10_amp_max)\n",
    "stddev = np.std(log10_amp_max)\n",
    "normed = (log10_amp_max - mean) / stddev\n",
    "amplitude_threshold = 4  # in units of stddev\n",
    "indices = np.where(np.abs(normed) <= amplitude_threshold)[0]\n",
    "rfstream = rf.RFStream(map(rfstream.__getitem__, indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count remaining stations and traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_networks = []\n",
    "for net in networks:\n",
    "    stream = rfstream.select(network=net)\n",
    "    nstations = len(set([trace.stats.station for trace in stream]))\n",
    "    ntraces = len(stream)\n",
    "    print(f\"{net}: {nstations}/{init_nstations[net]} stations kept after quality control\")\n",
    "    print(f\"{net}: {ntraces}/{init_ntraces[net]} radial RFs kept after quality control\")\n",
    "    if nstations == 0 or ntraces == 0:\n",
    "        empty_networks.append(net)\n",
    "for empty in empty_networks:\n",
    "    networks.remove(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Networks {', '.join(empty_networks)} have no more traces after quality control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure delay time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpsb(trace: rf.rfstream.RFTrace):\n",
    "    \"\"\"\n",
    "    Finds the time of the first local maximum of trace\n",
    "    \"\"\"\n",
    "    ind = argrelmax(trace.data)[0][0]\n",
    "    return trace.times()[ind] - (trace.stats.onset - trace.stats.starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_stack(stream: rf.RFStream) -> rf.RFStream():\n",
    "    \"\"\"\n",
    "    TO BE USED ONLY WHEN STREAM ONLY CONTAINS TRACES FROM THE SAME STATION\n",
    "    RFStream.stack() forces stacking for separate ids, including channels\n",
    "    Access original obspy Stream.stack() to stack BHR and HHR channels\n",
    "    Copies meta data as in RFStream.stack()\n",
    "    \"\"\"\n",
    "    _stream = stream.copy()  # Stream.stack() operates in place\n",
    "    stack = super(rf.RFStream, _stream).stack(group_by=\"{network}.{station}\")\n",
    "    assert len(stack) == 1\n",
    "    tr = stream[0]\n",
    "    data = stack[0].data\n",
    "    header = {}\n",
    "    for entry in (\n",
    "        \"network\",\n",
    "        \"station\",\n",
    "        \"sampling_rate\",\n",
    "        \"phase\",\n",
    "        \"moveout\",\n",
    "        \"station_latitude\",\n",
    "        \"station_longitude\",\n",
    "        \"station_elevation\",\n",
    "        \"processing\",\n",
    "    ):\n",
    "        if entry in tr.stats:\n",
    "            header[entry] = tr.stats[entry]\n",
    "    _tr = rf.rfstream.RFTrace(data=data, header=header)\n",
    "    if \"onset\" in tr.stats:\n",
    "        onset = tr.stats.onset - tr.stats.starttime\n",
    "        _tr.stats.onset = _tr.stats.starttime + onset\n",
    "    return rf.RFStream(_tr)\n",
    "\n",
    "\n",
    "def stack_by_station(stream: rf.RFStream) -> rf.RFStream():\n",
    "    # Station dictionary\n",
    "    rf_station_dict = defaultdict(rf.RFStream)\n",
    "    for trace in stream:\n",
    "        rf_station_dict[trace.stats.station] += rf.RFStream([trace])\n",
    "\n",
    "    # stack stations individually, otherwise station coordinates also get stacked\n",
    "    stacks = rf.RFStream()\n",
    "    for v in rf_station_dict.values():\n",
    "        stacks += station_stack(v)\n",
    "\n",
    "    return stacks\n",
    "\n",
    "\n",
    "def get_delays(stream: rf.RFStream) -> rf.RFStream():\n",
    "    # Get delay of each stack\n",
    "    for stack in stream:\n",
    "        delay = get_tpsb(stack)\n",
    "        if delay >= 0:\n",
    "            stack.stats[\"delay\"] = delay\n",
    "        else:\n",
    "            print(\n",
    "                f\"Negative delay obtained for {stack.stats.network}.{stack.stats.station}\"\n",
    "            )\n",
    "            stream.remove(stack)\n",
    "\n",
    "    return stream.sort([\"delay\", \"network\", \"station\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfstacks = stack_by_station(rfstream)  # stream with station stacks\n",
    "rfstacks = get_delays(rfstacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot traces, stacks and maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(stream: rf.RFStream, save_dir: str=\".\", show: bool=False):\n",
    "    lats = np.array([trace.meta.station_latitude for trace in stream])\n",
    "    lons = np.array([trace.meta.station_longitude for trace in stream])\n",
    "    nets = np.array([trace.meta.network for trace in stream], dtype=str)\n",
    "    delays = np.array([trace.meta.delay for trace in stream])\n",
    "\n",
    "    fig, region, projection = australia_basemap()\n",
    "    pygmt.makecpt(cmap=\"hot\", truncate=[0, 0.8], series=[0, 1, 0.1],background=\"o\", reverse=True)\n",
    "    fig.plot(\n",
    "        region=region,\n",
    "        projection=projection,\n",
    "        x=lons,\n",
    "        y=lats,\n",
    "        style=f\"tc\",\n",
    "        fill=delays,\n",
    "        cmap=True,\n",
    "        size=np.full_like(lons, 0.25),\n",
    "    )\n",
    "    fig.colorbar(\n",
    "        region=region,\n",
    "        projection=projection,\n",
    "        frame=[\"af+lDelay Time TPsb (s)\", f\"y+lmax={delays.max():.2f}\"],\n",
    "        position=\"JBC+ef\",\n",
    "    )\n",
    "    if save_dir is not None:\n",
    "        mapfile = os.path.join(save_dir, \"delay_map.pdf\")\n",
    "        fig.savefig(mapfile)\n",
    "    if show:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = False\n",
    "if not dry_run:\n",
    "    # Make output directories\n",
    "    now = (datetime.now()).strftime(format=\"%Y%m%d_%H%M%S\")\n",
    "    processedroot = os.path.join(dataroot, \"..\", \"processed\")\n",
    "    outdir = os.path.join(processedroot, now)\n",
    "\n",
    "    for net in networks:\n",
    "        os.makedirs(os.path.join(outdir, net))\n",
    "\n",
    "\n",
    "    def plot_rfs_stacks_map(network, stream, stacks):\n",
    "        outdir = os.path.join(processedroot, now, network)\n",
    "        stations = set([stack.stats.station for stack in stacks])\n",
    "        # plot RFs at each station\n",
    "        for station in stations:\n",
    "            rfs = stream.select(station=station)\n",
    "            plot_name = os.path.join(outdir, f\"{station}.pdf\")\n",
    "            fig = rfs.plot_rf(\n",
    "                fname=plot_name,\n",
    "                fig_width=4,\n",
    "                fillcolors=(\"green\", None),\n",
    "                trace_height=0.1,\n",
    "                scale=3,\n",
    "                show_vlines=True,\n",
    "                trim=(-2, 6),\n",
    "            )  # this figure needs some bits to be moved around\n",
    "\n",
    "        # Plot the stacked RFs of the network\n",
    "        plot_name = os.path.join(outdir, f\"stacks.pdf\")\n",
    "        fig = stacks.plot_rf(\n",
    "            fname=plot_name,\n",
    "            fig_width=4,\n",
    "            fillcolors=(\"green\", None),\n",
    "            trace_height=0.1,\n",
    "            scale=3,\n",
    "            show_vlines=True,\n",
    "            trim=(-2, 6),\n",
    "            info=(),\n",
    "        )  # customise this plot to use a colourmap\n",
    "\n",
    "        # Plot map of network delay times\n",
    "        plot_map(stacks, outdir)\n",
    "\n",
    "\n",
    "    # Plots for each network\n",
    "    Parallel(n_jobs=-1)(\n",
    "        delayed(plot_rfs_stacks_map)(\n",
    "            net, rfstream.select(network=net), rfstacks.select(network=net)\n",
    "        ) for net in networks\n",
    "    )\n",
    "\n",
    "    # Plot the full map\n",
    "    plot_map(rfstacks, outdir, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the delay times in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dry_run:\n",
    "    with open(os.path.join(outdir, \"delays.txt\"), \"w\") as f:\n",
    "        for stack in rfstacks:\n",
    "            f.write(\n",
    "                f\"{stack.meta.network:4}\\t{stack.meta.station:6}\\t{stack.meta.station_longitude}\\t{stack.meta.station_latitude}\\t{stack.stats.delay:.3f}\\n\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aussedthick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
